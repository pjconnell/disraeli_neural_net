{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing Code\n",
    "\n",
    "### Each of the boxes of code in this section should be run once (in the order they are here). \n",
    "\n",
    "To run a box, click on it (so you can see your cursor blinking inside the box) then press \"cntrl+enter\" (or click the \"run\" button at the top of this page)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import spacy\n",
    "import requests\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions \n",
    "def read_file(filepath):\n",
    "    \n",
    "    with open(filepath) as f:\n",
    "        str_text = f.read()\n",
    "    \n",
    "    return str_text\n",
    "\n",
    "def separate_punc(doc_text):\n",
    "    return [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']\n",
    "\n",
    "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words, threshold):\n",
    "    '''\n",
    "    INPUTS:\n",
    "    model : model that was trained on text data\n",
    "    tokenizer : tokenizer that was fit on text data\n",
    "    seq_len : length of training sequence\n",
    "    seed_text : raw string text to serve as the seed\n",
    "    num_gen_words : number of words to be generated by model\n",
    "    '''\n",
    "    \n",
    "    # Final Output\n",
    "    output_text = []\n",
    "    \n",
    "    # Intial Seed Sequence\n",
    "    input_text = seed_text\n",
    "    \n",
    "    # Confidendence (note this is generated by the model and may be over-confident; in the future may calibrate with a Bayesian NN)\n",
    "    confidence = 1\n",
    "    \n",
    "    # Create num_gen_words\n",
    "    for i in range(num_gen_words):\n",
    "        \n",
    "        # Take the input text string and encode it to a sequence\n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "\n",
    "        # Pad sequences to our trained rate (50 words in the video)\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
    "\n",
    "        # Predict Class Probabilities for each word\n",
    "        pred_word_ind = model.predict_classes(pad_encoded, verbose=0)[0]\n",
    "        wd_confi = model.predict(pad_encoded, verbose=0)[0].max()\n",
    "        confidence = confidence*wd_confi\n",
    "\n",
    "        # Make sure addition of this word won't push us out of our confidence level\n",
    "        if confidence < threshold:\n",
    "            confidence = confidence/wd_confi # adjust confidence for reporting\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            # Grab word\n",
    "            pred_word = tokenizer.index_word[pred_word_ind] \n",
    "\n",
    "            # Update the sequence of input text (shifting one over with the new word)\n",
    "            input_text += ' ' + pred_word\n",
    "\n",
    "            output_text.append(pred_word)\n",
    "        \n",
    "    # Make it look like a sentence.\n",
    "    confidence = round(confidence*100,2)\n",
    "    print(f\"Confidence is: {confidence}%\")\n",
    "    return ' '.join(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\spacy\\util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.0) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Load spaCy NLP\n",
    "nlp = spacy.load('en_core_web_sm',disable=['parser', 'tagger','ner'])\n",
    "nlp.max_length = 1198623\n",
    "\n",
    "# Load the concatenated letters for processing\n",
    "d = read_file('concatenated_letters.txt')\n",
    "tokens = separate_punc(d)\n",
    "\n",
    "# organize into sequences of tokens\n",
    "train_len = 50+1 # 50 training words , then one target word\n",
    "\n",
    "# Empty list of sequences\n",
    "text_sequences = []\n",
    "\n",
    "for i in range(train_len, len(tokens)):\n",
    "    \n",
    "    # Grab train_len# amount of characters\n",
    "    seq = tokens[i-train_len:i]\n",
    "    \n",
    "    # Add to list of sequences\n",
    "    text_sequences.append(seq)\n",
    "    \n",
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_sequences)\n",
    "sequences = tokenizer.texts_to_sequences(text_sequences)\n",
    "\n",
    "vocabulary_size = len(tokenizer.word_counts)\n",
    "\n",
    "# Create Numpy Matrix\n",
    "sequences = np.array(sequences)\n",
    "\n",
    "# Initialize Matrices\n",
    "X = sequences[:,:-1] # first 49 words in the sequence\n",
    "y = sequences[:,-1] # last word in the sequence\n",
    "seq_len = X.shape[1] # set sequence length for \"generate_text\" tool\n",
    "\n",
    "\n",
    "# load trained model\n",
    "model = load_model('Disraeli_bot1.h5')\n",
    "tokenizer = load(open('Disraeli_bot1','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This section lets you interact with the Disraeli neural net (a.k.a. \"Disraeli-bot\")\n",
    "\n",
    "You can run the box below as many times as you want. When you run it, it will ask for a \"prompt\" - this is analogous to the first sentence (or two - you can type as much as you want, 25-50 words is ideal) you type in a Gmail email. Then, the Disraeli-bot will spit out up to the next 25 words that Gmail would suggest continuing with (the suggestion powered by the neural net trained on Disraeli's correspondence) provided the confidence level in the prediction does not fall below a specified level (I put the default at 50%, but you can tweak that by changing the \"threshold=0.X\" argument).\n",
    "\n",
    "**A few notes for Nick** - this performs better on topics covered in the letters than out (I had some from 1868 and 1857 from https://www.jstor.org/stable/10.3138/j.ctt9qh93p). You probably understand much better what the content is, but it looks to me like this is a lot of personal correspondence, so perhaps not super topical for our purposes? Also of note - I didn't get a chance to clean the letters yet, so the footnote annotations and \"EBSCO Host checked out to paul.connell@columbia.edu\", etc. are, unfortunately, included in the nerual net. These are all things that we can fix easily, but take time. Also, the more letters we can feed it (I hit my max allowance of 100 pages/day) the better the performance will get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give Disraeli-bot a prompt: Russia and Turkey are at war. Our means of supporting the Ottomans are\n",
      "Disraeli-bot continues with:...\n",
      "Confidence is: 32.45%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'of any sentimental tomfoolery Â®'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_text= input(\"Give Disraeli-bot a prompt: \")\n",
    "# seed_text = \"Given the opportunity to purchase half of the outstanding equity in the Suez company, which the Pasha is eager for in order to retire debt, I think\"\n",
    "print(\"Disraeli-bot continues with:...\")\n",
    "generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=25, threshold=0.3\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Odds and Ends** Use the pip istalls if you don't already have the relevant packages downloaded to your programming environment. The last box includes code to download the model from GitHub if it is not already saved locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install keras\n",
    "# %pip install spacy\n",
    "# %pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl\n",
    "# %pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz\n",
    "# %pip install tensorflow\n",
    "\n",
    "# %run -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load trained model and tokenizer from GitHub\n",
    "# url = \"https://raw.githubusercontent.com/pjconnell/disraeli_neural_net/main/Disraeli_bot1.h5\"\n",
    "# page = requests.get(url)\n",
    "# m = page.text\n",
    "# # # load model\n",
    "# model = load_model(m)\n",
    "\n",
    "# # load tokenizer\n",
    "# url = \"https://raw.githubusercontent.com/pjconnell/disraeli_neural_net/main/Disraeli_bot1\"\n",
    "# page = requests.get(url)\n",
    "# t = page.text\n",
    "# tokenizer = load(open(t,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
